---
layout: post
title: 'The Dance of Space: Geom/Topo/Dynam Mumble(6): Positive Semidefinite Matrix'
date: 2026-02-08 14:58:02
description: PSD, Riemannian/Information Geometry, Optimal Transport
tags: 
    - "Manifold"
    - "Differential Geometry"
categories: 
    - "Brain-Computer Interface"
featured: false
related_posts: true
related_publications: true
citation: true
math: true
toc:
  beginning: true
  sidebar: left
---

We've talked about the collection of positive definite matrices on several occasions already, each time focusing on different facets. On [the post]({% post_url 2026-02-23-Manifold(4)-Lie %}) on Lie group/algebra, 
we explained that it is not a Lie group but a smooth manifold, and then in [the later post]({% post_url 2026-02-24-Manifold(X)-metric %}), we saw that by introducing Riemannian metric we could turn 

$$
\mathrm{SPD}(n)
= \{ A \in \mathbb{R}^{n \times n} \mid A^\top = A,\; A > 0 \}.
$$

into a Riemannian manifold, upon which we could calculate distance and geodesics. Specifically, we spent sometime going over the computation of affine invariant distance:

$$
d(A,B)
= \left\|
\log\left(A^{-1/2} B A^{-1/2}\right)
\right\|_F = \left(
\sum_{i=1}^n (\log \lambda_i)^2
\right)^{1/2}.
$$

where $$\lambda_i$$ are eigenvalues of $$A^{-1}B$$. 

In this blog, I want to dive in a little deeper into this Riemannian manifold with the affine-invariant metric. 


## 1] Geometry of SPD(n)

Let

$$
\mathrm{SPD}(n)
= \{ A \in \mathbb{R}^{n\times n} \mid A^\top = A,\; A > 0 \}.
$$

This is a smooth manifold of dimension $\frac{n(n+1)}{2}$.

It can be identified with the symmetric space

$$
\mathrm{SPD}(n)
\cong
\mathrm{GL}(n)/\mathrm{O}(n).
$$

---

# 1Ô∏è‚É£ Deriving the Affine-Invariant Metric from First Principles

## Step 1: Desired symmetry

We want a Riemannian metric satisfying:

1. Smoothness
2. Positive definiteness
3. Invariance under congruence transformations

$$
A \mapsto M A M^\top
\quad \text{for } M \in \mathrm{GL}(n).
$$

This invariance is the key principle.

---

## Step 2: Tangent space

At a point $A \in \mathrm{SPD}(n)$,

$$
T_A \mathrm{SPD}(n)
=
\mathrm{Sym}(n),
$$

the space of symmetric matrices.

So tangent vectors are symmetric matrices $H,K$.

---

## Step 3: Reduce to identity

Because of invariance, it suffices to define the metric at $I$.

At $I$, the most natural inner product on symmetric matrices is the Frobenius one:

$$
g_I(H,K)
=
\mathrm{tr}(HK).
$$

This is $\mathrm{O}(n)$-invariant.

---

## Step 4: Transport to arbitrary point

Given $A \in \mathrm{SPD}(n)$, map it to $I$ via:

$$
A^{-1/2} A A^{-1/2} = I.
$$

Transport tangent vectors:

$$
H \mapsto A^{-1/2} H A^{-1/2}.
$$

Define:

$$
g_A(H,K)
=
\mathrm{tr}\!\left(
A^{-1} H A^{-1} K
\right).
$$

---

## ‚úÖ Final Metric

$$
\boxed{
g_A(H,K)
=
\mathrm{tr}(A^{-1} H A^{-1} K)
}
$$

This is the **affine-invariant Riemannian metric**.

---

# 2Ô∏è‚É£ Geodesics

Solving the geodesic equation gives:

$$
\gamma(t)
=
A^{1/2}
\left(
A^{-1/2} B A^{-1/2}
\right)^t
A^{1/2}.
$$

Distance:

$$
d(A,B)
=
\left\|
\log(A^{-1/2} B A^{-1/2})
\right\|_F.
$$

If $\lambda_i$ are eigenvalues of $A^{-1}B$, then

$$
d(A,B)
=
\left(
\sum_{i=1}^n (\log \lambda_i)^2
\right)^{1/2}.
$$

---

# 3Ô∏è‚É£ Why Curvature Is Negative

Recall:

$$
\mathrm{SPD}(n)
\cong
\mathrm{GL}(n)/\mathrm{O}(n).
$$

This is a noncompact Riemannian symmetric space.

General theorem:

- If $G/K$ is noncompact semisimple,
- Then sectional curvature is nonpositive.

Since $\mathrm{GL}(n)$ is noncompact and $\mathrm{O}(n)$ is compact,

$$
\mathrm{SPD}(n)
$$

has nonpositive sectional curvature.

---

## Intuition

Use the logarithm map:

$$
A \mapsto \log A.
$$

Eigenvalues become:

$$
\lambda_i \mapsto \log \lambda_i.
$$

Distance becomes Euclidean in log-eigenvalue coordinates:

$$
d^2 = \sum (\log \lambda_i)^2.
$$

Logarithm turns multiplicative changes into additive ones.

Multiplicative geometry ‚Üí hyperbolic-like geometry ‚Üí negative curvature.

Geodesics spread apart faster than Euclidean ones.

---

# 4Ô∏è‚É£ Connection to Wasserstein Geometry

Consider zero-mean Gaussian measures:

$$
\mathcal{N}(0,A), \quad \mathcal{N}(0,B).
$$

Their 2-Wasserstein distance is:

$$
W_2^2(A,B)
=
\mathrm{tr}(A)
+
\mathrm{tr}(B)
-
2\,\mathrm{tr}
\left(
(A^{1/2} B A^{1/2})^{1/2}
\right).
$$

This induces the **Bures metric** on SPD.

---

## Comparison

Affine-invariant metric:

- Arises from group symmetry
- Negative curvature
- Multiplicative geodesics

Wasserstein/Bures metric:

- Arises from optimal transport
- Related to quantum information
- Different curvature structure

Both treat SPD matrices as a curved manifold,
but from different geometric principles.

---

# 5Ô∏è‚É£ Connection to Fisher Information

Consider the family of Gaussians:

$$
p(x;A)
=
\frac{1}{(2\pi)^{n/2} \det(A)^{1/2}}
\exp\left(
-\frac12 x^\top A^{-1} x
\right).
$$

Compute the Fisher information metric:

$$
g_A(H,K)
=
\mathbb{E}
\left[
\partial_H \log p \;
\partial_K \log p
\right].
$$

One obtains:

$$
\boxed{
g_A(H,K)
=
\frac12
\mathrm{tr}(A^{-1} H A^{-1} K)
}
$$

Up to a constant factor,
this is exactly the affine-invariant metric.

---

## Interpretation

The affine-invariant metric is:

- The Fisher information metric
- The natural gradient metric
- The intrinsic geometry of Gaussian covariance matrices

Thus:

SPD geometry = Information geometry of Gaussians.

---

# üåü Big Picture

SPD(n) simultaneously appears as:

1. A symmetric space:
   $$
   \mathrm{GL}(n)/\mathrm{O}(n)
   $$

2. A negatively curved manifold under affine-invariant metric

3. The covariance manifold of Gaussians under Fisher metric

4. The state space of quantum density matrices under Bures metric

This is why it appears in:

- Optimal transport
- Information geometry
- Machine learning
- Natural gradient descent
- Quantum information theory
