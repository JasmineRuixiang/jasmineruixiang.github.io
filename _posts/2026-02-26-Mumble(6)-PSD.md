---
layout: post
title: 'The Dance of Space: Geom/Topo/Dynam Mumble(6): Positive Semidefinite Matrix'
date: 2026-02-26 14:58:02
description: PSD, Riemannian/Information Geometry, Optimal Transport
tags: 
    - "Manifold"
    - "Differential Geometry"
categories: 
    - "Brain-Computer Interface"
featured: false
related_posts: true
related_publications: true
citation: true
math: true
toc:
  beginning: true
  sidebar: left
---

We've talked about the collection of positive definite matrices on several occasions already, each time focusing on different facets. On [the post]({% post_url 2026-02-23-Manifold(4)-Lie %}) on Lie group/algebra, 
we explained that it is not a Lie group but a smooth manifold, and then in [the later post]({% post_url 2026-02-24-Manifold(X)-metric %}), we saw that by introducing Riemannian metric we could turn 

$$
\mathrm{SPD}(n)
= \{ A \in \mathbb{R}^{n \times n} \mid A^\top = A,\; A > 0 \}.
$$

into a Riemannian manifold, upon which we could calculate distance and geodesics. Specifically, we spent sometime going over the computation of affine invariant distance:

$$
d(A,B)
= \left\|
\log\left(A^{-1/2} B A^{-1/2}\right)
\right\|_F = \left(
\sum_{i=1}^n (\log \lambda_i)^2
\right)^{1/2}.
$$

where $$\lambda_i$$ are eigenvalues of $$A^{-1}B$$. 

In this blog, I want to dive in a little deeper into this Riemannian manifold with the affine-invariant metric. 

One more time, to recall the geometry of $$\mathrm{SPD}(n)$$

Let

$$
\mathrm{SPD}(n)
= \{ A \in \mathbb{R}^{n\times n} \mid A^\top = A,\; A > 0 \}.
$$

This is a smooth manifold of dimension $$\frac{n(n+1)}{2}$$.

It can be identified with the symmetric space

$$
\mathrm{SPD}(n)
\cong
\mathrm{GL}(n)/\mathrm{O}(n).
$$

Let's start by figuring out where the affine-invariant metric comes from.  

---

## 1] Deriving the Affine-Invariant Metric from First Principles

We want a Riemannian metric satisfying the following properties:

1. Smoothness
2. Positive definiteness
3. Invariance under congruence transformations

$$
A \mapsto M A M^\top
\quad \text{for } M \in \mathrm{GL}(n).
$$

This invariance is the key principle. Sidenote: this is different from similarity transformation ($$A \mapsto M A M^{-1}
\quad \text{for } M \in \mathrm{GL}(n)$$).

Why do we need such invariance under congruence? Because SPD matrices represent quadratic forms.

If a quadratic form is $$q(x) = x^\top A x$$ and we change coordinates $$y = Mx$$, then $$q(y) = x^\top (M^\top A M) x$$. Up to swapping left/right order, this is exactly congruence.

Consequently, congruence encodes the change of coordinates for quadratic forms. And we want the metric to be invariance under such coordinate changes. 

On the other hand, it's not hard to show that SPD stay SPD under congruence. Why? Let $$A \in \mathrm{SPD}(n)$$. Then for any nonzero vector $$x$$,

$$
x^\top (M A M^\top) x
= (M^\top x)^\top A (M^\top x).
$$

Since $M^\top x \neq 0$ whenever $x \neq 0$,

So:

$$
M A M^\top \in \mathrm{SPD}(n).
$$

Thus $$\mathrm{SPD}(n)$$ is closed under congruence transformations.

---
Before we continue, it's worth clarifying what "affine-invariant metric" mean. We say the metric is `affine-invariant` if:

$$
d(A,B)
= d(M A M^\top,\; M B M^\top), \forall M \in GL(n)
$$

(should this be actually termed "congruence-invariant"? )

Meaning:

> Distance does not depend on the coordinate system.

that means if we reparameterize space (this is the underlying vector space of $$x, y$$, not the ambient space where $$\mathrm{SPD}(n)$$ lives) by any invertible linear map, such defined distances between SPD matrices will remain unchanged. This is one key property we want to acquire. 

Consequently, in some sense this is the “right” symmetry. Because SPD matrices encode:

- Inner products
- Covariance matrices
- Metrics on vector spaces

Changing basis of the underlying vector space

$$
v \mapsto M v
$$

should not change intrinsic geometry. So the natural symmetry group acting on SPD is:

$$
A \mapsto M A M^\top.
$$

This also explains why we do not use similarity invariance. Notice that similarity preserves eigenvalues (not proved here), whereas congruence preserves:

- Positive definiteness
- Inertia (Sylvester’s law)

But eigenvalues change under congruence. In other words, congruence corresponds to changing coordinates in the domain, not changing the linear operator as a map. $$\mathrm{SPD}$$ matrices are not being viewed as operators — they are being viewed as quadratic forms. This distinction is crucial.

Back to our goal. Now we are clear that we ideally require invariance under congruence. Notice that $$\mathrm{SPD}(n)$$ is an open subset of symmetric matrices, so at any point $$A \in \mathrm{SPD}(n)$$,

$$
T_A \mathrm{SPD}(n)
= \mathrm{Sym}(n),
$$

the space of symmetric matrices (I'll leave it to the readers for the proof). So tangent vectors are symmetric matrices $$H,K$$, and then our goal is to find $$g_A(H, K)$$ that depends smoothly on $$A \in \mathrm{SPD}(n)$$.

Because of invariance, it suffices to define the metric at $$I$$ (echoeing the definition of Lie derivative). Why? Any $$A \in \mathrm{SPD}(n)$$ can be sent to $$I$$ by congruence of $$A^{-1/2}$$. Thus, if we know the metric at $$I$$, invariance determines it everywhere.

At $$I$$, the most natural inner product on symmetric matrices is the Frobenius one:

$$
g_I(H,K)
= \mathrm{tr}(HK).
$$

This is $\mathrm{O}(n)$-invariant.

Finally, to transport to arbitrary point, given $$A \in \mathrm{SPD}(n)$$, map it to $$I$$ via:

$$
A^{-1/2} A A^{-1/2} = I.
$$

Transport tangent vectors:

$$
H \mapsto A^{-1/2} H A^{-1/2}.
$$

Define:

$$
g_A(H,K)
= \mathrm{tr}\!\left(
A^{-1} H A^{-1} K
\right).
$$

Consequently, the final metric is of the form

$$
\boxed{
g_A(H,K)
= \mathrm{tr}(A^{-1} H A^{-1} K)
}
$$

This is indeed the **affine-invariant Riemannian metric** we saw above.

To prove that it's indeed a Riemannian metric, we need to prove that it varies smoothly over the input domain...

---

## 2] Geodesics

The natural next step is to calculate the geodesics given such Riemannian metric. Solving the geodesic equation gives:

$$
\gamma(t)
= A^{1/2}
\left(
A^{-1/2} B A^{-1/2}
\right)^t
A^{1/2}.
$$

Distance:

$$
d(A,B)
= \left\|
\log(A^{-1/2} B A^{-1/2})
\right\|_F.
$$

If $\lambda_i$ are eigenvalues of $A^{-1}B$, then

$$
d(A,B)
= \left(
\sum_{i=1}^n (\log \lambda_i)^2
\right)^{1/2}.
$$

Please refer to [this blog]({% post_url 2026-02-24-Manifold(X)-metric %}) for deriving the distance formula based on eigenvalues. 

---

## 3] Why Curvature Is Negative

Recall:

$$
\mathrm{SPD}(n)
\cong
\mathrm{GL}(n)/\mathrm{O}(n).
$$

This is indeed a __noncompact__ Riemannian symmetric space.

Notice that we have a general theorem:

> If $$G/K$$ is noncompact semisimple, then sectional curvature is nonpositive.

Since $\mathrm{GL}(n)$ is noncompact and $\mathrm{O}(n)$ is compact,

$$
\mathrm{SPD}(n)
$$

has nonpositive sectional curvature.

The intuition for the above is that if we investigate using the logarithm map:

$$
A \mapsto \log A.
$$

Eigenvalues become:

$$
\lambda_i \mapsto \log \lambda_i.
$$

Distance becomes Euclidean in log-eigenvalue coordinates:

$$
d^2 = \sum (\log \lambda_i)^2.
$$

Logarithm turns multiplicative changes into additive ones. Consequently, multiplicative geometry is turned into hyperbolic-like geometry which entails negative curvature.

It's also true that in this case geodesics spread apart faster than Euclidean ones.

---

## 4] Connection to Wasserstein Distance

Consider zero-mean Gaussian measures:

$$
\mathcal{N}(0,A), \quad \mathcal{N}(0,B).
$$

Their 2-Wasserstein distance is:

$$
W_2^2(A,B)
= \mathrm{tr}(A) + \mathrm{tr}(B) - 2\,\mathrm{tr}
\left(
(A^{1/2} B A^{1/2})^{1/2}
\right).
$$

This induces the **Bures metric** on SPD.

If we do a direct comparison

Affine-invariant metric:

- Arises from group symmetry
- Negative curvature
- Multiplicative geodesics

Wasserstein/Bures metric:

- Arises from optimal transport
- Related to quantum information
- Different curvature structure

Both treat SPD matrices as a curved manifold, but from different geometric principles.

---

## 5] Connection to Fisher Information

Consider the family of Gaussians:

$$
p(x;A) = \frac{1}{(2\pi)^{n/2} \det(A)^{1/2}} \exp\left(-\frac12 x^\top A^{-1} x
\right).
$$

If we compute the Fisher information metric:

$$
g_A(H,K)
= \mathbb{E}
\left[
\partial_H \log p \;
\partial_K \log p
\right].
$$

One obtains:

$$
\boxed{ g_A(H,K)
= \frac12
\mathrm{tr}(A^{-1} H A^{-1} K)
}
$$

Up to a constant factor. Indeed, this is exactly the affine-invariant metric.

Consequently, this offers another interpretation of the affine-invariant metric as

- The Fisher information metric
- The natural gradient metric
- The intrinsic geometry of Gaussian covariance matrices

Thus:

> SPD geometry = Information geometry of Gaussians.

---

## 6] Summary

$$\mathrm{SPD}(n)$$ simultaneously appears as:

1. A symmetric space:
   $$
   \mathrm{GL}(n)/\mathrm{O}(n)
   $$

2. A negatively curved manifold under affine-invariant metric

3. The covariance manifold of Gaussians under Fisher metric

4. The state space of quantum density matrices under Bures metric

This is why it appears in optimal transport, information geometry, machine learning, and etc. 
