---
layout: post
title: Rotational dynamics in neural population
date: 2025-08-16 18:30:16
description: introduce neural latent dynanics from jPCA 
tags: latent-dynamics, neural-population, dimensionality-reduction
categories: latent-dynamics
featured: true
related_posts: true
related_publications: true
citation: true
toc:
  beginning: true
  sidebar: left
math: true
---

Many years later, when I reflect back on the first quarter of the 21st century studies on computational neuroscience and  brain-computer interface (BCI), among papers on fancy Neural Network based decoders and clinical breakthroughs expanding from cursor and motor BCI to speech and vision, I might still recollect a distant afternoon when I first heard the name Mark Churchland, and more specifically, neural population dynamics and jPCA. I perhaps first read the paper {% cite jpca %} at least a decade after it came out, but the astonishing finding and the elegance of the algorithm, together with its implicit influences on shaping my thoughts of neural populations made it a classic enduring the test of time. This post is both an exploration and a summary, where I will extract a few key components from the article {% cite jpca %}, specifically its dynamical systems interpretation and then summarize the jPCA algorithm. 

## Dynamical Systems Perspective
A traditional perspective characeterizes neural activities from the primary motor cortex (M1) as representing the corresponding movement parameters. Equivalently, we could write out a parametric equation:

$$
r_n(t) = f_n(param_{1}(t), param_{2}(t), param_{3}(t), ...) 
$$

where $r_n(t)$ is the firing rate for the nth neuron, tuned by the corresponding function $f_n$. Alternatively, another perspective based on neural population encoding which reflect behavior parameters not on the single neuron level, but on the population level, is written as follows, which characterize a __dynamical system__ perspective:

$$
\dot{r}(t) = f(r(t)) + u(t)
$$

In this view, the dynamics, i.e., the evolution of population response encodes the movement parameters. Here u(t) is an unknown external input. 

## Quasi-rthymic Responses 
As made clear in the article, the critical finding of this study is that reaching, a non-oscillatory movement (unlike the swimming leech or a walking monkey), leads to a quasi-oscillatory neural trajectory. More surprisingly, the rotations are distinct not by reaching curvatures. Specifically, as the authors summaried, the trajectories have the following primary properties

> 
> 2asdfasasdfdf
> 3asdfasdf


## jPCA
Based on the dynamical systems perspective, since it's the time-dependent structure that we focus, a naive simple PCA is not sufficent to extract such temporal structures from neural activities, since PCA is not specificall designed for incapsulating dynamical structures. Here Churchland et al. developed an algorithm called jPCA to reoslve this issue. Specifically, it finds orthonormal axes (thus basis which define linear subspaces) which capture the strongest rotational components from subspace identified by PCA (to ensure that the rotational dynamics come from subspaces that efficiently "represent" the high dimensional neural space). Conseuqently, this is equivalent to rotating the PCA projections to help us "see" the rotation most clearly (as shown in video below). In the paper the authors chose the PCA dimension as 6, and the data projected from the 6-D PCA space to the first 2 jPCA components, thus a plane which captures the strongest rotations, is displayed to reveal the underlying oscillatory structure. 

## Discussions
The extracted neural trajectory is only "quasi-oscillatory", and usually exists for barely 1 cycle. 

## Open Questions
The jPCA method stems from dissecting the rotation component away from the general linear transformation. Can this be further stripped away from PCA? 



