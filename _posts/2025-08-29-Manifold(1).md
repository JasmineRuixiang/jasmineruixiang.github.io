---
layout: post
title: "Differentiable Manifold (1): Rigorous Definition (in progress)"
date: 2025-08-29 02:32:56
description: Rigorous definition of manifold and related topology concepts
tags: 
    - "Geometry Concepts/Tools"
    - "Topology Concepts/Tools"
categories: 
    - "Differential Geometry"
featured: true
related_posts: true
related_publications: true
citation: true
math: true
toc:
  beginning: true
  sidebar: left
---


### Preface 

Starting with this blog, I'll gradually introduce the core elements and the corresponding theories of (differentiable/smooth) manifold, which is, without any undue exaggeration or affected self-indulgence, the most fundamental arean upon which modern geometry unfolds (other than thoeries of curves and surfaces in $$\mathbb{R}^3$$). 

It's only after I seriously learned manifold that I started to appreciate its elegant geometric intuition (unintuited indeed or not easy to grasp at first glance sometimes) and its abstraction and extensions of our known, visually perceived $$\mathbb{R}^3$$ into higher dimensional space. It grants us infinite power to have a glimpse of what we are not quite possible at all for our entire lives to interpret and still acquire the confidence to draw conclusions on properties, hierarchies, and variations in the spave above us. 

As the first blog of the entire manifold Omnibus series, I aim to cover the rigorous definition of manifold, and a general introduction to its properties and different categories, to set the basis for further rigorous discussions. 

I would refrain from diverting to much from the many interesting discussions (but will review together the definition) of topological space, topology, open sets, Hausdorff space, and homeomorphism.  

### Something dark, or darker
One last note to keep before we starting diving in, especially for readers from computational/systems neuroscience who probably have heard of the concept `neural manifold`. For the past few decades, as the technologies of simultaneous recordings of multiple neurons quickly evolve, data recorded as an entire neural population has gradually become a solid reality for many subdomains of neuroscience, and the level of data analysis promptly and adaptively shifts from the single-neuron perspective to neural population analysis. Many theories have been developed to cope with such high dimensional data (could be as many as several hundreds), like the dynamical system perspective as [my previous two blogs covered]({% post_url 2025-08-16-jPCA %}, {% post_url 2025-08-25-Constraint-Learning %}), or neural manifold. This is really not a novel idea, as in many domains there's abundance of observation that among the high dimensional data there exists some low dimensional structure that captures the `patterns` of data. 

However, in most cases there's virtually nothing lost if we simply swap the word "neural manifold" into, say, "__low dimensional structure__". What worries me is that at least up to now there is no theoretical proof that a collected neural population is indeed a (at least topological) manifold. Also, from an ontological perspective, because other than employing this word itself, there's very few rigorous adaptation or usage of the many theorems and properties associated to a manifold, the true essence behind the entire domain of manifold theory is left untouched at all. Indeed, we might argue that at a figurative level such neural manifold is a nice symbol for building up intuition, but there's still a conceptual subtlety that the very first motivation of a manifold is to extend the familiar Euclidean space around us to higher dimensional spaces. In other words, the charm of manifolds shines in the high dimensional space, which, without further notice, might comletely mislead people into linking "manifold" with "low dimesional space". To be fair, in computational/systems neurscience, even when "neural manifold" is used to indicate "low dimensional space", it may still be 10 or 30, which for mathematicians are usually "high" (high vs low is a relative concept. I don't think there's a disagreement with regard to the aboslute "high"). For neuroscientists, "low dimension" is low because of its direct comparison to the original space in $$\mathbb{R}^{384}$$, for example; for a geometer, both $$\mathbb{R}^{10}$$ and $$\mathbb{R}^{384}$$ are "high dimensional space" because they extend beyond $$\mathbb{R}^{3}$$. 

I never doubt that some low dimensional structure is imbedded in neural population, as countless research has corroborated it. And I deeply appreciate the remarkable wisdom and significant efforts others have paid along this line of research under the name of neural manifold. In the end, I'm just hoping concepts to stay clear and to minimize the downplay of any important concepts that are both aesthetically appearling and fundamentally stunning. I'm reluctant to observe those ideas get muddled, mumbled, and straggled among hypes and later turned into buzzwords that, at the down-to-earth applied level, mistakes its potential and hides the key questions regarding how to adapt the abstract manifold concepts into codable algorithms, or at the abstract level noisify our perception of the world (as many other instances already in an awkard situation, like "computation" or "representation"). 

Perhaps I'm being a little over-reactive? 

Or...perhaps not so surprising, in recent years among Deep Learning there's more and more serious consideration and introduction of embedding geometry/topology into the modeling pipelines (geometric deel learning, interested readers might want to check out Michael Bronstein). I highly enjoy the geometric approaches whether in DL or neuroscience, and I'm very glad that I live in this era when I could witness the entire trajectory of geometry involvement. Meanwhile, I'll do my best to clarify things and introduce more into the pure beauty of geometry. Enough sentiment, now let's jump in.


### Some topology 



### Topological Manifold



### Smooth Manifold