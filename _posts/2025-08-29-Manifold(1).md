---
layout: post
title: "Differentiable Manifold (1): Rigorous Definition (in progress)"
date: 2025-08-29 02:32:56
description: Rigorous definition of manifold and related topology concepts
tags: 
    - "Geometry Concepts/Tools"
    - "Topology Concepts/Tools"
categories: 
    - "Differential Geometry"
featured: true
related_posts: true
related_publications: true
citation: true
math: true
toc:
  beginning: true
  sidebar: left
---


### Preface 

Starting with this blog, I'll gradually introduce the core elements and the corresponding theories of (differentiable/smooth) manifold, which is, without any undue exaggeration or affected self-indulgence, the most fundamental arean upon which modern geometry unfolds (other than thoeries of curves and surfaces in $$\mathbb{R}^3$$). 

It's only after I seriously learned manifold that I started to appreciate its elegant geometric intuition (unintuited indeed or not easy to grasp at first glance sometimes) and its abstraction and extensions of our known, visually perceived $$\mathbb{R}^3$$ into higher dimensional space. It grants us infinite power to have a glimpse of what we are not quite possible at all for our entire lives to interpret and still acquire the confidence to draw conclusions on properties, hierarchies, and variations in the spave above us. 

As the first blog of the entire manifold Omnibus series, I aim to cover the rigorous definition of manifold, and a general introduction to its properties and different categories, to set the basis for further rigorous discussions. 

I would refrain from diverting to much from the many interesting discussions (but will review together the definition) of topological space, topology, open sets, Hausdorff space, and homeomorphism.  

### A snapshot
The following might touch upon numerous unfamiliar terms and concepts, no worries I will cover them all as time unfolds. For now, let's get a little intuition and some impressionistic perception of this subject. 

Examples of manifold include both objects we know and some more abstractly constructed entities: $$\mathbb{R}^n$$, any onpen subsets of a manifold, $$M \times N$$ (if $$M$$ and $$N$$ are manifolds), the familiar $$S^n$$ and donut $$S^1 \times S^1$$, the (open) Mobius strip, Klein bottle $$K = I \times I / \sim$$, the projective plane $$\mathbb{RP}^n\cong S^n/\sim$$ (with the equivalence relation $$v \sim -v$$). 

An interesting example is the Grassmanian Manifold: $$Gr_k (\mathbb{R}^m) = \{ \mathrm{k\ dimensional\ vector\ subspaces\ of} \; \mathbb{R}^m \}$$, where $$0 \leq k \leq m$$. This is a compact manifold with dimensions $$k(m-k)$$ (Interested readers might come up with a guess or proof). Interestingly, $$Gr_1 (\mathbb{R}^m) \cong \mathbb{RP}^{m-1}$$. 

Since manifold is literally the backbone of moder differential geometry which has evolved into countless sub-branches and domains, it's impossible to even sample a fair amount in these blogs. Consequently, I'll be mainly focusing the following: 

- Definitions of smooth manifolds
- Submanifolds and embeddings
- Tangent and cotangent spaces
  - $$p \in M, dim(M) = n, T_p N \cong \mathbb{R}^n$$
  - $$T_p^{*} M $$, the cotangent space, as the dual vector space of $$T_p M$$
- Tangent and cotangent bundles
  - $$\pi: TM (\mathrm{2n\ dimensional}) \rightarrow M$$, where $$\pi^{-1}(\{ p\}) = T_p M$$
- Tangent and cotangent fields
  - $$X$$ as a vector field, $$X(p) \in T_pM, \forall p \in M$$, tracing out a flow on $$M$$
  - Cotangent fields are differential 1-forms, if $$f: M \rightarrow \mathbb{R}$$ is smooth, $$p \in M$$, then $$d_pf \in T_p^{*}M$$
- Differnetial $$k$$-forms on manifold $$M$$
  - 0-forms: functions on $$M$$
  - 1-forms: cotangent fields
  - 2-forms: sections of the $$k$$th exterior power of $$T^{*}N$$
  - de Rham derivatie: $$d: \Omega^{k}M \rightarrow \Omega^{k+1}M$$
  - For $$M$$ compact and orientable, $$\omega \in \Omega^n M$$, $$\int_{M} \omega \in \mathbb{R}$$
- General Stokes's Theorem
  - If M is compact, oriented, with boundary, n-dimensional and $$\omega \in \Omega^{n-1}M$$, then $$\int_{M}d\omega = \int_{\partial M} \omega$$
- Lie group and Lie algebra



### Something dark, or darker
One last note to keep before we starting diving in, especially for readers from computational/systems neuroscience who probably have heard of the concept `neural manifold`. For the past few decades, as the technologies of simultaneous recordings of multiple neurons quickly evolve, data recorded as an entire neural population has gradually become a solid reality for many subdomains of neuroscience, and the level of data analysis promptly and adaptively shifts from the single-neuron perspective to neural population analysis. Many theories have been developed to cope with such high dimensional data (could be as many as several hundreds), like the dynamical system perspective as [my previous two blogs covered]({% post_url 2025-08-16-jPCA %}, {% post_url 2025-08-25-Constraint-Learning %}), or neural manifold. This is really not a novel idea, as in many domains there's abundance of observation that among the high dimensional data there exists some low dimensional structure that captures the `patterns` of data. 

However, in most cases there's virtually nothing lost if we simply swap the word "neural manifold" into, say, "__low dimensional structure__". What worries me is that at least up to now there is no theoretical proof that a collected neural population is indeed a (at least topological) manifold. Also, from an ontological perspective, because other than employing this word itself, there's very few rigorous adaptation or usage of the many theorems and properties associated to a manifold, the true essence behind the entire domain of manifold theory is left untouched at all. Indeed, we might argue that at a figurative level such neural manifold is a nice symbol for building up intuition, but there's still a conceptual subtlety that the very first motivation of a manifold is to extend the familiar Euclidean space around us to higher dimensional spaces. In other words, the charm of manifolds shines in the high dimensional space, which, without further notice, might comletely mislead people into linking "manifold" with "low dimesional space". To be fair, in computational/systems neurscience, even when "neural manifold" is used to indicate "low dimensional space", it may still be 10 or 30, which for mathematicians are usually "high" (high vs low is a relative concept. I don't think there's a disagreement with regard to the aboslute "high"). For neuroscientists, "low dimension" is low because of its direct comparison to the original space in $$\mathbb{R}^{384}$$, for example; for a geometer, both $$\mathbb{R}^{10}$$ and $$\mathbb{R}^{384}$$ are "high dimensional space" because they extend beyond $$\mathbb{R}^{3}$$. Finally, manifold not only extends $$\mathb{R}^n$$ to $$\mathbb{R}^N$$, where $$n >> N$$, but more importantly entirely discards the many constraints of Euclidean space and works with more general spaces (indeed, as in the shift of focus of intrinsic vs extrinsic properties). 

I never doubt that some low dimensional structure is imbedded in neural population, as countless research has corroborated it. And I deeply appreciate the remarkable wisdom and significant efforts others have paid along this line of research under the name of neural manifold. In the end, I'm just hoping concepts to stay clear and to minimize the downplay of any important concepts that are both aesthetically appearling and fundamentally stunning. I'm reluctant to observe those ideas get muddled, mumbled, and straggled among hypes and later turned into buzzwords that, at the down-to-earth applied level, mistakes its potential and hides the key questions regarding how to adapt the abstract manifold concepts into codable algorithms, or at the abstract level noisify our perception of the world (as many other instances already in an awkard situation, like "computation" or "representation"). 

Perhaps I'm being a little over-reactive? 

Or...perhaps not so surprising, in recent years among Deep Learning there's more and more serious consideration and introduction of embedding geometry/topology into the modeling pipelines (geometric deel learning, interested readers might want to check out Michael Bronstein). I highly enjoy the geometric approaches whether in DL or neuroscience, and I'm very glad that I live in this era when I could witness the entire trajectory of geometry involvement. Meanwhile, I'll do my best to clarify things and introduce more into the pure beauty of geometry. Enough sentiment, now let's jump in.


### A bit of topology 



### Manifold 101: Topological manifold



### The real domain: Smooth manifold

Given $$f: u \subset \mathbb{R}^n \rightarrow \mathbb{R}$$, where $$u$$ is an open set, $$f$$ is $$C^k$$ if the $$k$$th derivative $$\frac{\partial^k f}{\partial x_j^k}$$ exists and is continuous $$\forall 1 \leq j \leq n$$. Likewise, for a multivariable function $$f: u \subset \mathbb{R}^n \rightarrow \mathbb{R}^m$$, $$f = (f_1, f_2, \dots f_m)$$ is $$C^k$$ if $$f_i$$ is $$C^k \; \forall i$$. If we take $$k$$ to be $$\intfy$$, then $$f$$ is called a smooth. In my blogs, whenever any function is called differentiable without specifying the $$k$$th order, we will assume $$k$$ as $$\infty$$ and thus a differentiable function is the same as a smooth function. A differentiable manifold is the same as the smooth manifold, both I'll use interchangeably. 


The definiton of homeomorphism and charts allow us to pull functional analysis from $$C^{\infty}(M)$$ or $$C^{\infty}(M, N)$$ on $$M$$ into $$\mathbb{R^n}$$ itself and thus we could proceed with techqniues built within the Euclidean space. Later when defining tangent/cotangent space from the geometric standpoint, we will see another side of the same story. 
### A few others? 