<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Learning and constraints (in progress) | Ruixiang Li </title> <meta name="author" content="Ruixiang Li"> <meta name="description" content="Employ perturbations of neural manifold to explore learning constraints"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jasmineruixiang.github.io/blog/2025/Constraint-Learning/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.css"> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/katex.min.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.18/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ruixiang</span> Li </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Learning and constraints (in progress)</h1> <p class="post-meta"> Created in August 25, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Learning</a>   <a href="/blog/tag/neural-manifold"> <i class="fa-solid fa-hashtag fa-sm"></i> Neural Manifold</a>   <a href="/blog/tag/dimensionality-reduction"> <i class="fa-solid fa-hashtag fa-sm"></i> Dimensionality Reduction</a>     ·   <a href="/blog/category/brain-computer-interface"> <i class="fa-solid fa-tag fa-sm"></i> Brain-Computer Interface</a>   </p> </header> <article class="post-content"> <div id="table-of-contents"> <ul id="toc" class="section-nav"> <li class="toc-entry toc-h1"> <a href="#spatial-constraints-sadtler-etal-2014">Spatial constraints (Sadtler et.al. 2014)</a> <ul> <li class="toc-entry toc-h2"><a href="#experiment-setup">Experiment setup</a></li> <li class="toc-entry toc-h2"> <a href="#decoding-paradigm">Decoding paradigm</a> <ul> <li class="toc-entry toc-h3"><a href="#dimensionality-reduction-technique">Dimensionality reduction technique</a></li> <li class="toc-entry toc-h3"> <a href="#intuitive-mapping">Intuitive mapping</a> <ul> <li class="toc-entry toc-h4"> <a href="#derivation-of-the-iterative-filtering-equation">Derivation of the iterative filtering equation</a> <ul> <li class="toc-entry toc-h5"><a href="#step-1-linear-gaussian-system">Step 1: Linear Gaussian system</a></li> <li class="toc-entry toc-h5"><a href="#step-2-perform-z-scoring">Step 2: Perform z-scoring</a></li> <li class="toc-entry toc-h5"><a href="#step-3-apply-kalman-filter">Step 3: Apply Kalman Filter</a></li> </ul> </li> </ul> </li> </ul> </li> <li class="toc-entry toc-h2"> <a href="#perturbation-method">Perturbation method</a> <ul> <li class="toc-entry toc-h3"><a href="#perturbation-as-permutation">Perturbation as permutation</a></li> <li class="toc-entry toc-h3"> <a href="#select-perturbed-mappings">Select perturbed mappings</a> <ul> <li class="toc-entry toc-h4"><a href="#step-1-find-the-candidate-set">Step 1: Find the candidate set</a></li> <li class="toc-entry toc-h4"><a href="#step-2-open-loop-velocities-prediction-per--perturbation">Step 2: Open-loop velocities prediction per perturbation</a></li> <li class="toc-entry toc-h4"><a href="#step-3-determine-potential-perturbations">Step 3: Determine potential perturbations</a></li> </ul> </li> </ul> </li> <li class="toc-entry toc-h2"> <a href="#quantifiable-metric">Quantifiable metric</a> <ul> <li class="toc-entry toc-h3"><a href="#amount-of-the-learning">Amount of the learning</a></li> <li class="toc-entry toc-h3"><a href="#after-effects">After-effects</a></li> <li class="toc-entry toc-h3"><a href="#principalcanonical-angles">Principal/canonical angles</a></li> </ul> </li> <li class="toc-entry toc-h2"> <a href="#discussions">Discussions</a> <ul> <li class="toc-entry toc-h3"><a href="#required-changes-in-preferred-directions">Required changes in preferred directions</a></li> <li class="toc-entry toc-h3"><a href="#selection-of-intrinsic-dimensionality">Selection of intrinsic dimensionality</a></li> <li class="toc-entry toc-h3"><a href="#measurement-of-cumulative-shared-variance">Measurement of cumulative shared variance</a></li> </ul> </li> <li class="toc-entry toc-h2"><a href="#conclusions">Conclusions</a></li> </ul> </li> <li class="toc-entry toc-h1"> <a href="#dynamical-constraints-oby-etal-2025">Dynamical Constraints (Oby et.al. 2025)</a> <ul> <li class="toc-entry toc-h2"><a href="#different-views-of-the-high-dimeensional-neural-space">Different views of the high dimeensional neural space</a></li> <li class="toc-entry toc-h2"><a href="#task-1">Task 1:</a></li> <li class="toc-entry toc-h2"><a href="#task-2-it-task">Task 2: IT task</a></li> <li class="toc-entry toc-h2"><a href="#task-3-instructed-path-task">Task 3: Instructed path task</a></li> <li class="toc-entry toc-h2"><a href="#discussions-1">Discussions</a></li> <li class="toc-entry toc-h2"><a href="#conclusions-1">Conclusions</a></li> </ul> </li> <li class="toc-entry toc-h1"><a href="#discussions-2">Discussions</a></li> <li class="toc-entry toc-h1"><a href="#conclusions-2">Conclusions</a></li> </ul> </div> <hr> <div id="markdown-content"> <p>This blog covers two papers, with the emphasis on the first to …</p> <p>Both spatial (neural manifold view) and temporal (dynamical system view) on constraints of neural activities.</p> <h1 id="spatial-constraints-sadtler-etal-2014">Spatial constraints (Sadtler et.al. 2014)</h1> <h2 id="experiment-setup">Experiment setup</h2> <p>For <a class="citation" href="#Sadtler2014">(“Neural Constraints on Learning,” 2014)</a>, two male Rhesus macaques were trained to perform closed-loop BCI cursor task (Radial 8). Around 85-91 neural units (threshold-crossings) were recorded. The experiment pipeline is demonstrated below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <img src="/assets/img/learning_constraint/Fig_1a.png" class="img-fluid rounded z-depth-1" width="70%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Adapted from Fig. 1a in <a class="citation" href="#Sadtler2014">(“Neural Constraints on Learning,” 2014)</a>. Note that on the right hand side the authors already presented where to place the two kinds of perturbation. The color scheme (green, yellow, and black) is consistent throughout figures in this paper. </div> <h2 id="decoding-paradigm">Decoding paradigm</h2> <h3 id="dimensionality-reduction-technique">Dimensionality reduction technique</h3> <p>The control space is just 2D because the decoder output is cursor velocities in \(\mathbb{R}^2\), illustrated as black line in Fig.2 black line (Note: it’s actually a 2D plane, but here for simplicity shown as a black line (\(\mathbb{R}^1\))).</p> <p>They used Factor Analysis ({cite (Factor-analysis methods for higher-performance neural prostheses) }{cite (Gaussian Process Factor analysis)}; I’ll write a blog on GPFA later) to extract what they called the “intrinsic manifold”, which captures the co-modulation patterns among the recorded neural population. This is shown as the underlying yellow plane in Fig.2 (might be confusing, but it’s not the 2D control space). Note that at the time of publication, neural manifold was not yet in a popular trend, so the authors briefly characterized the term “intrinsic manifold” with the following illustration:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <img src="/assets/img/learning_constraint/Fig_1b.png" class="img-fluid rounded z-depth-1" width="65%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Adapted from Fig. 1b in <a class="citation" href="#Sadtler2014">(“Neural Constraints on Learning,” 2014)</a>. . </div> <p>The authors further elaborated on the intrinsic manifold and its associated dimensionality at the end of the paper. For consistency of comparisons, Sadtler et. al. used a <strong>linear</strong> 10-D intrinsic manifold across all days. They then performed some offline analysis to explore if 10 is a legitimate choice. Specifically, they estimated the intrinsic dimensionality (EID) as the peak of maximal cross-validated log-likelihood (LL). In panel a the vertical bars represent the standard error of LL from across 4 cross-validation folds. Panel b. shows EID for all days and both 2 monkeys. The authors also showed the LL difference between 10D manifold vs manifold with EID (panel c., with units being the the number of standard errors of LL for the EID model). From panel c. the authors observed that 89% of days the 10-D manifold only differs within one standard error of LL with the EID manifold. Panel d. indicates the cumulative explained variance by the 10-D manifold. Notice that 10 dimensions already explained almost all neural variance.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <img src="/assets/img/learning_constraint/Fig_4.png" class="img-fluid rounded z-depth-1" width="70%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Adapted from Fig.4 in <a class="citation" href="#Sadtler2014">(“Neural Constraints on Learning,” 2014)</a>. </div> <p>The factor analysis method works in the following way (I’ll keep the same notation as the paper). Let’s assume the high dimensional neural signal (here the z-scored spike counts) acquired every 45ms time bin is denoted as \(u \in \mathbb{R}^{q \times 1}\) (naturally, \(q\) neural units), and \(z \in \mathbb{R}^{10}\) the latent variable. Factor analysis assumes the observed neural activity is related to the unobservable latent variables under a Gaussian distribution:</p> \[\begin{equation} u \mid z \sim N(\Lambda z + \mu, \psi) \end{equation}\] <p>where the latent vector is assumed to come from</p> \[\begin{equation} z \sim N(0, I) \end{equation}\] <p>Here the covariance matrix \(\psi\) is diagonal. Consequently, the intrinsic manifold is defined on the span of the columns of \(\Lambda\), and each column of \(\Lambda\) represents a latent dimension where \(z\) encodes the corresponding projections/coordinates. All three parameters \(\Lambda, \mu, \psi\) are estimated from <strong>Expectation-Maximization (EM)</strong> method (I’ll also write a blog about this later, especially how it as a classical inferenc engine is closely related to Evidence Lower Bound (<strong>ELBO</strong>), a populat loss/objective function for modern-day generative models based on DNN like VAE and Diffusion).</p> <h3 id="intuitive-mapping">Intuitive mapping</h3> <p>The intuitive mapping is selected by fitting a modified Kalman Filter ({cite Wu W. Gao Y., Bayesian population decoding of motor cortical activity using a Kalman filter}). Specifically, for each <strong>z-scored</strong> spike count \(z_t\), after obtaining the posterior mean \(\hat{z}_{t} = E[z_t \mid u_t]\) and <strong>z-scoring</strong> each dimension (these z-scorings are important, which will be stressed a multiple times later), the authors started with the common linear dynamical system (LDS) assumption of Kalman Filter:</p> \[\begin{align} x_t \mid x_{t-1} &amp;\sim N(Ax_{t-1} + b, Q) \\ \hat{z}_t \mid x_t &amp;\sim N(Cx_t + d, R) \end{align}\] <p>The parameters \(A,b,Q,C,d,R\) are obtained by maximum likelihood estimation, where \(x_t\) is the estimate of monkey’s intended velocity (label for the data). Since the spike counts and the latent factors were both <strong>z-scored</strong> and the calibration kinematics were centered, \(\mu = d = b = 0\).</p> <p>Consequently, by filtering the goal is to estimate \(\hat{x}_{t} = E[x_t \mid \hat{z}_{1}, \;, ... \;, \hat{z}_{t}]\). The authors directly gave out the formula below to express \(\hat{x}_t\) in terms of the final decoded velocity at the previous step \(\hat{x}_{t-1}\) and the current z-scored spike count \(u_{t}\):</p> \[\begin{equation} \hat{x}_t = M_1 \hat{x}_{t-1} + M_2 u_t \end{equation}\] \[\begin{equation} M_1 = A - KCA \end{equation}\] \[\begin{equation} M_2 = K\Sigma_{z}\beta \end{equation}\] \[\begin{equation} \beta = \Lambda^T(\Lambda \Lambda^T + \Psi)^{-1} \end{equation}\] <p>where \(K\) is the steady-state Kalman gain matrix. As part of the process of z-scoring the latent factors, \(\Sigma_z\) is a <strong>diagonal</strong> matrix whose diagonal element (\(p, p\)) refers to the inverse of standard deviation of the \(pth\) factor. Since both spike counts and latent factors are <strong>z-scored</strong>, the perturbed mappings (see in the next section) “would not require a neural unit to fire outside of its observed spike count range”.</p> <p>The above formula might sound confusing, so I present below a detailed derivation. It’s not so complicated but readers who are not interested in derivation feel free to skip it.</p> <h4 id="derivation-of-the-iterative-filtering-equation">Derivation of the iterative filtering equation</h4> <p>I’ll derive the above formula (5 - 8) in the following 3 steps. In the end, this is nothing brand new and elusive.</p> <blockquote> <p>Step 1: Obtain the posterior of \(z \mid u\)</p> <p>Step 2: z-score the latents</p> <p>Step 3: Apply Kalman filter</p> </blockquote> <h5 id="step-1-linear-gaussian-system">Step 1: Linear Gaussian system</h5> <p>I’ll start with a well-known fact about linear Gaussian system (this derivation is also the core of Gaussian Process and Kalman Filter; Stop for a second and marvel again at the all-encompassing power of Gaussian distribution). Assume two random vectors \(z \in \mathbb{R}^m\) and \(x \in \mathbb{R}^n\) which follow the Gaussian distribution:</p> \[\begin{equation} p(z) = N(z \mid \mu_z, \Sigma_z) \end{equation}\] \[\begin{equation} p(x \mid z) = N(x \mid Az + b, \Omega) \end{equation}\] <p>The above illustrates a <strong>linear Gaussian system</strong>. Note that \(A \in \mathbb{R}^{n \times m}\). Consequently, the correponsding joint distribution \(p(z, x) = p(z)p(x \mid z)\) is also a Gaussian with an \((m + n)\) dimensional random vector:</p> \[\begin{equation} p(z, x) = N( \begin{bmatrix} z \\ x \end{bmatrix} \mid \tilde{\mu}, \tilde{\Sigma}) \end{equation}\] <p>where</p> \[\begin{align} \tilde{\mu} &amp;= \begin{bmatrix} \mu_z \\ A\mu_z + b \end{bmatrix} \\ \tilde{\Sigma} &amp;= \begin{bmatrix} \Sigma_z &amp; \Sigma_z A^T \\ A\Sigma_z &amp; A\Sigma_z A^T + \Omega \end{bmatrix} \end{align}\] <p>The above could be easily derived from matching the corresponding moments, so I will not show in full details. From this joint Gaussian, we could thus easily continue to write out the posterior distribution:</p> \[\begin{equation} p(z \mid x) = N(z \mid \mu', \Sigma') \end{equation}\] <p>where</p> \[\begin{equation} \mu' = \mu_z + \Sigma_z A^T(A\Sigma_z A^T + \Omega)^{-1}(x - (A \mu_z + b)) \end{equation}\] \[\begin{equation} \Sigma' = \Sigma_z - \Sigma_z A^T(A\Sigma_z A^T + \Omega)^{-1}A\Sigma_z \end{equation}\] <p>The above posterior is known as <strong>Bayes’ rule for Gaussians</strong>. It states that if both the prior \(p(z)\) and the likelihood \(p(x \mid z)\) are Gaussian, so is the posterior \(p(z \mid x)\) (equivalently, Gaussian prior is a <strong>conjugate prior</strong> of Gaussian likelihood or Gaussians are <strong>closed under updating</strong>, <a class="citation" href="#pml2Book">(Murphy, 2023)</a> P29). One interesting fact is that although the posterior mean is a linear function of \(x\), the posterior covariance is entirely independent of \(x\). This is a peculiar property of Gaussian distribution (Interested readers please see more explanations in <a class="citation" href="#pml2Book">(Murphy, 2023)</a> sections 2.3.1.3, 2.3.2.1-2, and 8.2). Finally, keen readers might already perceive the equation (15,16) prelude the form of the Kalman Filter posterior update equations.</p> <p>From the above posterior Gaussian form, by plugging in the notations specified in (1-2) with \(z = z_t, \; x = u_t, \; \mu_z = 0, \; \Sigma_z = I \;, A = \Lambda, \; b = \mu \;, \Omega = \Psi\) we obtain the following:</p> \[\begin{equation} p(z_t \mid u_t) = N(z_t \mid \mu_{post}, \Sigma_{post}) \end{equation}\] <p>where</p> \[\begin{align} \mu_{post} &amp;= 0 + I \Lambda^T(\Psi + \Lambda I \Lambda^T)^{-1}(u_t - (\Lambda 0 + \mu)) \\ &amp;= \Lambda^T(\Psi + \Lambda \Lambda^T)^{-1}u_t \end{align}\] <p>and</p> \[\begin{align} \Sigma_{post} &amp;= I - I\Lambda^T(\Psi + \Lambda I \Lambda^T)^{-1}\Lambda I \\ &amp;= I - \Lambda^T(\Psi + \Lambda \Lambda^T)^{-1}\Lambda \end{align}\] <p>I deliberately used a different set of notations for the posterior linear Gaussian system, so if you are interested please do this little derivation on your own. Since \(\hat{z}_t = E[z_t \mid u_t]\), from above we know that</p> \[\begin{equation} \hat{z}_t = \Lambda(\Psi + \Lambda \Lambda^T)^{-1}u_t \end{equation}\] <h5 id="step-2-perform-z-scoring">Step 2: Perform z-scoring</h5> <p>The second step is to z-score the posterior mean \(\hat{z}_t\), which, here, is dividing each position of this vector by the corresponding standard deviation:</p> \[\begin{equation} \hat{z}_{t, z-scored} = \begin{bmatrix} \hat{z}_{t}^{1} / \sigma_{1} \\ \hat{z}_{t}^{2} / \sigma_{2} \\ \vdots \\ \hat{z}_{t}^{p} / \sigma_{p} \end{bmatrix} = \begin{bmatrix} \frac{1}{\sigma_1} &amp; 0 &amp; 0 &amp;\cdots &amp; 0 \\ 0 &amp; \frac{1}{\sigma_2} &amp; 0 &amp; \cdots &amp; 0 \\ \vdots &amp; &amp; \ddots &amp; &amp; \vdots \\ 0 &amp; 0 &amp; 0 &amp; \cdots &amp; \frac{1}{\sigma_{p}} \end{bmatrix} \hat{z}_t = \Sigma_z \hat{z}_t \end{equation}\] <p>For simplicity, for the below I’ll replace \(\hat{z}_{t, z-scored}\) with \(\hat{z}_t\).</p> <h5 id="step-3-apply-kalman-filter">Step 3: Apply Kalman Filter</h5> <p>As in Step 1, let me right down the filtering equation for a pure Kalman Filter based on the Gaussian linear assumption made in (9-10) (For the following I’ll drop off \(b, d\) since they are 0). The notations below might be a little messy, but I want to keep it rigorous. The hat on \(x, P\) refer to estimates not ground truth, and \(t \mid t-1\) indicates prior estimation while \(t \mid t\) indicates posterior estimation at time point \(t\).</p> \[\begin{align} \hat{x}_{t|t-1} &amp;= A\hat{x}_{t-1|t-1} \\ \hat{P}_{t|t-1} &amp;= A\hat{P}_{t-1|t-1}A^T + Q \\ K_t &amp;= \hat{P}_{t|t-1}C^T(C\hat{P}_{t|t-1}C^T + R)^{-1}\\ \hat{x}_{t|t} &amp;= \hat{x}_{t|t-1} + K_t(\hat{z}_{t} - C\hat{x}_{t|t-1}) \\ \hat{P}_{t|t} &amp;= (I - K_tC)\hat{P}_{t|t-1} \end{align}\] <p>Again, we play the trick of substitution, starting with (27):</p> \[\begin{align} \hat{x}_{t\mid t} &amp;= \hat{x}_{t \mid t-1} + K_t(\hat{z}_{t} - C\hat{x}_{t \mid t-1}) \\ &amp;= A\hat{x}_{t-1 \mid t-1} + K_t(\hat{z}_t - CA\hat{x}_{t-1 \mid t-1}) \\ &amp;= (A - K_tCA)\hat{x}_{t-1 \mid t-1} + K_t \hat{z}_t \\ &amp;= (A - K_tCA)\hat{x}_{t-1 \mid t-1} + K_t\Sigma_z( \Lambda^T(\Psi + \Lambda \Lambda^T)^{-1}u_t) \\ &amp;= (A - K_tCA)\hat{x}_{t-1 \mid t-1} + K_t\Sigma_z \Lambda^T(\Psi + \Lambda \Lambda^T)^{-1}u_t \end{align}\] <p>Finally, if we define \(M_1 = A - KCA\), \(M_2 = K\Sigma_z \beta\), \(\beta = \Lambda^T(\Psi + \Lambda \Lambda^T)^{-1}\) (formula (6-8)), we’d claim what we saw in (5):</p> \[\hat{x}_t = M_1 \hat{x}_{t-1} + M_2 u_t\] <p>What I wrote as \(\hat{x}_{t \mid t}\) is the posterior prediction which the authors denoted \(\hat{x}_{t}\) for simplicity (same logic for \(t-1\)). The only subtlety that remains here is that in the above derivation I used the dynamic Kalman Gain \(K_t\), calculated for every time point $t$. In the paper the authos utilized steady Kalman Gain (that’s why there’s no subscript \(t\)) but that’s basically iterate the above filtering equations many times with the given set of model parameters (\(A,Q,C,R\)) until \(K_t\) converges to some matrix \(K = \lim_{t \rightarrow \infty} K_t\), and then use that matrix for all time steps. Basically, you could just replace \(K\) with \(K_t\) without changing the backbone of the inference structure.</p> <p>Before we jump into the perturbation method, the formula (5) does inform us the central philosophy of Kalman Filter: it integrates model prediction by its specified linear dynamics and the observation together, to arrive at an optimal (I’ll not dive deep into what optimality represents here) posterior inference. Extracting out the linear relationship between prediction at timestep \(t\) and the previous step \(t-1\) together with the observation input would help understanding the perturbation method below.</p> <h2 id="perturbation-method">Perturbation method</h2> <p>Then the core methodology of this study is to change the BCI mapping so that the altered control space would be lying either within or outside of the insintric manifold. The paper does present some confusion as to how intuitive mapping and control space would be distinguished. My interpretation is that the control space refers to the ideal potential neural subspace for which to control the cursor optimally. Since within a short time neural connectivity is kept unaltered, the true intrinsic manifold is approximately invariant and thus the required potential neural subspace might not be reachable. By default the control space/intuitive mapping lies within the intrinsic manifold (that’s why it’s called “intuitive”, because that’s is what the neural network system has learned to achieve).</p> <p>The neuronal connectivity statistics is referred to as the natural co-modulation patterns.</p> <p>In short, a within-manifold perturbation only reoriented the control space such that it still resides in the intrinsic manifold (shown in Fig.3 red line). This does not require monkeys to readapt neuronal connectivity patterns to achieve such new control space. It only altered the function from the intrinsic manifold to cursor kinematics. On the other hand, an outside-manifold perturbation alters the control space allowing it to live off the intrinsic manifold (Fig.3 blue line). Notice that if such outside-manifold perturbation pushes the control space along the orthogonal subspace that passes through the original control space, then the mapping from the neural comodulation patterns to cursor kinematics is preserved (basically just project the altered control space to the intrinsic manifold, then would recover the original control space). However, the underlying comodulation/covariation patterns among the neural population are altered.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <img src="/assets/img/learning_constraint/Fig_1c.png" class="img-fluid rounded z-depth-1" width="45%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Adapted from Fig.1c in <a class="citation" href="#Sadtler2014">(“Neural Constraints on Learning,” 2014)</a>. </div> <p>After the perturbation, the authors observed if the monkeys could eventually learn to readapt to the new mapping, to achieve great cursor control performance. For within-manifold perturbation, the monkeys only need to learn to associate cursor kinemaitcs to a new set of neural comodulation patterns (still within reach because lying in the same intrinsic manifold). However, for outside-manifold perturbation, they had to generate new co-modulation patterns in order to reach outside of the existing intrinsic manifold. Consequently, the authors predicted that within-manifold perturbation is easier to learn compared to outside-manifold perturbation. The authors did find results to back up this claim and since they are not the main focus of this blog, I’ll refer interested readers to the original paper to take a look (FIgure 2).</p> <h3 id="perturbation-as-permutation">Perturbation as permutation</h3> <p>Other than that, I do want to dive deep into how such within/outside-manifold perturbations were implemented. Specifically, from the derivation section readers should be already familiar with equations (5-8), the intuitive mapping. The perturbed mappings are the corresponding modified versions.</p> <p>The within-manifold perturbation still manages to maintain the relationship between neural units to latent factors, but perturb that between latents and cursor kinematics: \(\hat{z}_{t}\) is permuted before going into the Kalman inference (multiplying with the Kalman Gain)(Figure 1 red). Since permutation is simply re-orientation, the within-manifold perturbation is equivalent to re-orientating the coordinate system within the manifold (the manifold is preserved because the row space of \(\Lambda^T\) is preserved (equation (7))). Mathematically,</p> \[\begin{align} \hat{x}_t = M_1 \hat{x}_{t-1} + M_{2, WM}u_t \\ M_{2, WM} = K\eta_{WM}\Sigma_z\beta \end{align}\] <p>and \(\eta_{WM}\) is a \(10 \times 10\) permutation matrix (10 because of the latent dimensionality)</p> <p>For outside-manifold perturbation, it changes the relationship between the neural units and latent factors by permuting \(u_t\) before passing it into factor analysis (Figure 1 blue). Specifically,</p> \[\begin{align} \hat{x}_t = M_1 \hat{x}_{t-1} + M_{2, OM}u_t \\ M_{2, OM} = K\Sigma_z\beta \eta_{OM} \end{align}\] <p>and \(\eta_{OM}\) is a \(q \times q\) permutation matrix (\(q\) is the number of neural units). The underlying logic is that in the <strong>neural space</strong> for \(u_t\), the monkeys might not be able to adapt to conteract the perturbation brought by permutation, since \(\eta_{OM}\) directly acts upon \(u_t\).</p> <h3 id="select-perturbed-mappings">Select perturbed mappings</h3> <p>The authors also devised a clever plan to dictate the specific permutation matrices to choose (for a permutation matrix with size \(k \times k\), there’re \(k!\) numbers of them) in three steps, with the central goal that the perturbed mapping would not be too difficult nor easy to learn:</p> <h4 id="step-1-find-the-candidate-set">Step 1: Find the candidate set</h4> <p>For within-manifold perturbations, all \(10!\) possible permutation matrices are treated as the candidate set. For outside-manifold perturbations, th strategy differs for two monkeys. For one monkey only permutations of nueral units with largetst modulation depths are selected. For the other monkey, the solution is to randomly put all units with the highest modulation depths into 10 groups of \(m\) each (the rest with low modulation forms an 11th group). The outside-manifold perturbation is formed by permutating these 10 groups instead of each unit (thus \(10!\) in total matching that of within-manifold perturbation).</p> <h4 id="step-2-open-loop-velocities-prediction-per--perturbation">Step 2: Open-loop velocities prediction per perturbation</h4> <p>The second step hinges on estimating the open-loop velocities for each candidate permutation. Specifically, it approximates the decoded cursor kinematics if the monkeys did not learn to adapt:</p> \[\begin{equation} x_{OL}^i = M_{2, P}u_{B}^i \end{equation}\] <p>where \(u_{B}^i\) is the mean z-scored spike counts across all trials on the \(i^{th}\) target(\(8\) in total), and \(P\) represents either \(OM\) or \(WM\). The method here echoes the dissection made explicity in equation(5), where the current step prediction \(\hat{x}_t\) is a linear combination of prediction from last step \(\hat{x}_{t-1}\) and neural activities at the present \(M_2 u_t\).</p> <h4 id="step-3-determine-potential-perturbations">Step 3: Determine potential perturbations</h4> <p>Finally, to determine a perturbation the authors compared the open-loop velocities under the perturbed mapping with those under the intuitive mapping for each target. These velocities should only differ in an acceptable range so the monkeys would not find it too simple nor difficult to learn. The authors quantified this metric by defining a range over differences in velocity angles and magnitude, and chose perturbations that fall in this specified range for all targets.</p> <h2 id="quantifiable-metric">Quantifiable metric</h2> <h3 id="amount-of-the-learning">Amount of the learning</h3> <p>To quantify the potential amount of learning under two perturbation kinds, the authors resorted primarily to two performance metric: (the change of) relative acquisition time and relative success rate across perturbation blocks. Specifically, as shown below, the black dot represents the intuitive mapping, while the red and blue dots indicate the imediate performance just after corresponding perturbations. Red and blue asterisks represent the best performance during the within the perturbation sessions. The dashed line indicates the maximum learning vector \(L_{max}\) (note that it starts on the red dot), and thus the aount of learning (\(A_i \in \mathbb{R}\)) is quantified as the length of the projection of the raw learning vector onto the maximum learning vector, normalized by the length of the maximum learning vector:</p> \[A_i = \frac{L_{raw, i} \cdot L_{max}}{\|L_{max}\|^2}\] <p>where \(i \in \{red, blue\}\). Pictorially, it’s illustrated as below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <img src="/assets/img/learning_constraint/Fig_2cd.png" class="img-fluid rounded z-depth-1" width="75%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Adapted from Fig.2c and Fig.2d in <a class="citation" href="#Sadtler2014">(“Neural Constraints on Learning,” 2014)</a>. </div> <p>Note that the asterisks in the above represent the time point/bin corresponding to <strong>maximal</strong> amount of learning. In real case, for each time bin the authors would pinpoint the end points for the learning vectors (for calculations in details, please refer to the METHODS section of the paper), and compute the amount of learning correspondingly (the red and blue learning vectors might end in different positions with a diferent set of relative acquisition time and success rate up to that time bin).</p> <p>The amount of learning for all sessions was presented above in the right pannel. Notice that a value of 1 indicates “complete” learning of the new relationship between the required neural co-modulation and cursor kinematics, reverting to the performance level of the intuitive control, while 0 indicates no learning. The authors did observe that there’s significant amount of learning for within-manifold perturbations than outside-manifold perturbation. To see changes in success rates and acquisition time during perturbation blocks, instead of a single metric \(L\) as shown above, the authors also plotted them separately as below:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <img src="/assets/img/learning_constraint/Ext_Fig_2.png" class="img-fluid rounded z-depth-1" width="80%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Adapted from Extended Fig.2 in <a class="citation" href="#Sadtler2014">(“Neural Constraints on Learning,” 2014)</a>. </div> <h3 id="after-effects">After-effects</h3> <p>A second metric Sadtler et. al. employed is observe how the monkeys performed as they reintroduce the intuitive mapping, or the so-called after-effects after washout of the perturbed mapping. Specifically, the after-effect is measured as the amount of performance imparement (tentative: acquisition time, success rate) at the beginning at the wash-out block (like how impairement was measured at the beginning of a perturbation block). A large wash-out effect indicates that the monkeys have learned and adapted to the perturbed mapping. For within-manifold perturbation, the authors did observe brief impaired performance but not so for outside-manifold perturbation, indicating that learning did occur during the former.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0 text-center"> <figure> <picture> <img src="/assets/img/learning_constraint/Ext_Fig_3.png" class="img-fluid rounded z-depth-1" width="70%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Adapted from Extended Fig.3 in <a class="citation" href="#Sadtler2014">(“Neural Constraints on Learning,” 2014)</a>. </div> <h3 id="principalcanonical-angles">Principal/canonical angles</h3> <p>To quantify the comparisons between the intuitive and the perturbed mappings, Sadtler et.al. also calculated the principal angles between two linear subspaces. Notice that by formula () above, both subspaces are spanned by the rows of \(M_2\) (\(M_{2, WM}\) for within-manifold perturbation, and \(M_{2, OM}\) for outside-manifold perturbation). Consuquently, the two principal angles specify the maximum and minimum angles of separation between the intuitive and the perturbed control spaces. Notice that since the spike counts are z-scored, the control spaces also center at the origin.</p> <p>Sidenote: How do principal angles relate with principal eigenvalues and principal curvatures?</p> <p>To give a short summary of principal angles calculation:</p> <p>Note the role of SVD decompsition.</p> <h2 id="discussions">Discussions</h2> <p>Since Sadtler et. al. employed closed-looop BCI control, they were able to causally alter the model/map from neural activities to the decoded cursor velocities.</p> <p>This paper highlights a potential methodology of BCI research: since the mapping from neural activities to control correlates is <strong>fully specified</strong>, thus could be causally perturbed to explore the corresponding changes of controlled behavior. This allowed the authors to <strong>design/know apriori</strong> the optimal/required neural activities (specified by the altered mapping) to achieve task success, and thus to observe if animals could generate such neural patterns.</p> <p>An outside-manifold perturbation does not necessarily specify that it lives in orthogonal subspace of the intrinsic manifold. Also, because here the intrinsic manifold is illustrated as a plane, in real world scenario, it is unlikely that it exists as a linear subspace. Consequently, specifying a space that is “orthogonal” to the potential manifold (nonlinear, other than a linear subspace) might be problematic.</p> <p>The amount of learning is entirely dependent upon performance itself, which is difficult to causally link to neural changes.</p> <p>For the amount of learning metric, why would 0 indicate no learning? Orthogonal learning?</p> <p>Notice that the after-effects analysis echoed a lot of research methodology in force-field or curl-field perturbation for cursor control in monkey motor control studies.</p> <p>The authors also showed that learning did not improve through sessions (readers might refer to Extended Figure 4 in <a class="citation" href="#Sadtler2014">(“Neural Constraints on Learning,” 2014)</a> for further information).</p> <p>The perspective and consideration that Sadtler et.al took to ensure alternative explanations for the observed distinction of learnability do not hold are informative. I enjoyed its rigorosity, especially when they considered perturbed maps which might be initialy difficult to learn and carefully implement the controls (demonstrate that they have controled). To not diverge from the main focus of this blog, I’ll not cover those dicussions. The way that the authors listed clearly alternative explanations and how they tackled each is a very inviting, powerful, and efficient way of writing.</p> <p>From the methods the authors used, they only estimated a linear manifold. According to {cite}, linear manfolds should require more dimensions than a nonlinear manifold which could explain similar amount of variance.</p> <p>The dissection of control into an estimation of intrinsic manifold (Factor Analysis) and then build an intuitive mapping (decoder, Kalman Filter) to relate the latent factors to cursor kinematics is different from directly mapping neural activities to movement. Such dissection becomes a common theme for the past two decades, with the emphasis on latent manifold structure beecomes increasingly popular. More than a theoretical refinement, practically speaking, such dissection also allows the authors to perform two different types of perturbation.</p> <p>Talk more here and also relate this to the nonlinear manifold paper 2025.</p> <p>For defining the candidate set of potential outside-manifold perturbation for the second monkey, while the group looping strategy is a clever way to equalize possible permutation matrices with within-manifold perturbation (\(10!\)), I’m not completely persuaded by the logic behind it. When explaning the logic for the second monkey outside-manifold perturbation, the authors stated that the within-maifold perturbation only permutes the neural space with \(10\) dimensions, while the outside-manifold perturbation on average deal with 39 dimensions (number of permuted units). Thus the monkey would have to search for more space for outside-manifold perturbation. I think the subtlety here lies in the fact that within-manifold perturbation is not performed on the level of the ambient neural space, but on the latent 10-dimensional space which is extracted out of the original neural space and each basis vector of the latent space is a <strong>linear combination</strong> of the neural units. Its is not explicitly clear to me whether/how these two spaces should be compared solely based on the dimensonality it carries.</p> <p>Additionally, though I do appreciate the flavor of group assignment (there’s even a flavor of group action here; anyway, permutation matrices form a permutation group), I am not sure if each of the \(10!\) permutations on groups of neural units is “equivalent” to a permutation among 10 latent axes.</p> <p>Another question is outside-manifold perturbation is not necessarily guaranteed to be outside the manifold?</p> <h3 id="required-changes-in-preferred-directions">Required changes in preferred directions</h3> <p>There’s one interesting method that I don’t have enough time to delve into, which is the calculation of changes in preferred directions for each neural unit. This is calculated to make sure that learning two perturbation types would require similar effort for the monkeys to adapt (interested readers might refer to Figure 3b in the paper). The authors began by discussing comparing the columns of \(M_2, \; M_{WM, or OM}\), which reflects how each neural unit impacts the decoded cursor kinematics. This strategy is not adopted because for the second monkey \(M_2\) and \(M_{OM}\) share many columns for the un-permuted columns, making it an unfair comparison. However, it’s informative if we associate this view of \(M_2 u_t\) by assiging each column of \(M_2\) with a coordinate in \(u_t\) with that mentioned in the principal angles section where rows of \(M_2\) represnet an axis upon which \(u_t\) is projected. These two perspectives which interpret linear matrix multiplication as either a <strong>transformation</strong> (of basis vectors in space) or a <strong>projection</strong> which will be further illustrated in an upcoming post.</p> <p>Then, the authors came up with another technique. They assumed that</p> <blockquote> <p>1] under perturbation the monkeys would still manage to keep the same cursor velocity in the intutive mapping,</p> <p>2] The perturbed firing rates should be as close as possible to those in the intuitive mapping</p> </blockquote> <p>and these two assumptions transform into a constrained optimization problem: Find \(u_p^{i}\) such that its Euclidean distance with \(u_B^{i}\) is minimized when \(M_2u_B^i = M_{2, P}u_p^i\):</p> <blockquote> \[u_p^{i, *} = \arg\min_{u_p^i} ||u_p^i - u_B^i||_2\] <p>s.t. \(M_2u_B^i = M_{2, P}u_p^i\)</p> </blockquote> <p>This can be solved in closed-form with Lagrange multipliers (for rigorosity, the inverse below should be replaced with the Moore-Penrose Pseudoinverse, unless \(M_{2, P}\) is full-rank, which I’m not sure I could theoretically make that claim). Due to limited space, I’ll not leave the proof to another blog on linear transformation, which I also illustrate its relationship with CCA and another paper (Juan Gallego, trajectory alignment):</p> \[\begin{equation} u_p^i = u_B^i + M_{2, P}^T(M_{2, P}M_{2, P}^T)^{-1}(M_2 - M_{2, P})u_B^i \end{equation}\] <p>where \(u_B^i\) is the mean normalized spike count vector across all trials for each target \(i\) in the basline blocks.</p> <p>Then the authors fit a standard cosine tuning model for each unit \(k\) with all targets:</p> \[\begin{equation} u_B^i(k) = m_k \cdot cos(\theta_i - \theta_B(k)) + b_k \end{equation}\] <p>where for each neural unit \(k\), its preferred direction is encoded as \(\theta_B(k)\), \(m_k\) the depth of modulation, \(b_k\) the model offset, \(\theta_i\) the direction of the \(ith\) target. Apply the same calculation for \(u_P^i\) to obtain the preferred direction \(\theta_P(k)\) for each unit \(k\) under the perturbaed mapping. Finally, the preferred direction changes (for each neural unit) is calculated as:</p> \[\begin{equation} \mid \theta_P(k) - \theta_B(k) \mid \end{equation}\] <h3 id="selection-of-intrinsic-dimensionality">Selection of intrinsic dimensionality</h3> <p>Usually we do not have a coherent and systematic way to detemrine the optimal intrinsic dimensionality. Here for factor analysis, based on its explicit probabilistic inference structure, the authors could easily compute the likelihood for cross-validated data.</p> <h3 id="measurement-of-cumulative-shared-variance">Measurement of cumulative shared variance</h3> <p>Based on equations (13), the original covariance of \(u\) is decomposed (with minor substitutions) into a shared component \(\Lambda \Lambda^T\) and an independent component \(\Psi\). In order to calculate the amount of shared variance along orthogonal directions within the manifold (notice this is a linear manifold), consequently, the authors calculated the eigenvalues of \(\Lambda \Lambda^T\) which present the shared variances, each corresponds to an orthonormalized latent dimension. This is similar to Churchland 2012 the last blog…</p> <h2 id="conclusions">Conclusions</h2> <p>The neural manifold reflects the inherent connectivity which constrains (in a short term) the potentially learnable patterns. Consequently, the neural connectivity network structure dictates possible neural patterns and corresponding behavior repertoire the animals are capable of performing.</p> <p>This paper strengthens my belief in the legit usability of the low dimensional structure among neural population, and more crucially the value of perturbation methods to causally verify the neural manifold. Specifically, the extraction of latent factors, other than directly mapping neural activties to cursor kinematics, not only adds more interpretability to the framework, but also provies a readily distinguishable strategy of within/outside-manifold perturbations. This reminds me of many other models with latent factors in between: (xxx, xxx, xxx, xxx).</p> <h1 id="dynamical-constraints-oby-etal-2025">Dynamical Constraints (Oby et.al. 2025)</h1> <h2 id="different-views-of-the-high-dimeensional-neural-space">Different views of the high dimeensional neural space</h2> <h2 id="task-1">Task 1:</h2> <h2 id="task-2-it-task">Task 2: IT task</h2> <h2 id="task-3-instructed-path-task">Task 3: Instructed path task</h2> <h2 id="discussions-1">Discussions</h2> <p>A dynamical system does not simply allow flowing back!</p> <h2 id="conclusions-1">Conclusions</h2> <h1 id="discussions-2">Discussions</h1> <p>These two studies offer powerful information that dimensionality reduction could be not just a visualization tool, but a causal summary of the underlying neural connectivity and anatomical constraints, which correlates to the neural computations that neural population could implement.</p> <p>Associating Sadtler 2014 with Churchland 2012, there’s a common convergence on using matrices to explore transformations. This again reinforces my idea that perhaps group theory needs to be rigorously introduced into neursocience for … (also associate with Barack and Kraukauer “Two views on the cognitive brain”, which relates <strong>computation</strong> to <strong>transformation of representations</strong> to explain cognitive phenomena)</p> <h1 id="conclusions-2">Conclusions</h1> </div> </article> <br> <hr> <br> If you found this useful, please cite this as: <blockquote> <p>Li, Ruixiang (Aug 2025). Learning and constraints (in progress). https://jasmineruixiang.github.io.</p> </blockquote> <p>or as a BibTeX entry:</p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">li2025learning-and-constraints-in-progress</span><span class="p">,</span>
  <span class="na">title</span>   <span class="p">=</span> <span class="s">{Learning and constraints (in progress)}</span><span class="p">,</span>
  <span class="na">author</span>  <span class="p">=</span> <span class="s">{Li, Ruixiang}</span><span class="p">,</span>
  <span class="na">year</span>    <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span>   <span class="p">=</span> <span class="s">{Aug}</span><span class="p">,</span>
  <span class="na">url</span>     <span class="p">=</span> <span class="s">{https://jasmineruixiang.github.io/blog/2025/Constraint-Learning/}</span>
<span class="p">}</span>
</code></pre></div></div> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="pml2Book" class="col-sm-8"> <div class="title">Probabilistic Machine Learning: Advanced Topics</div> <div class="author"> Kevin P. Murphy </div> <div class="periodical"> Jul 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Sadtler2014" class="col-sm-8"> <div class="title">Neural constraints on learning</div> <div class="author"> </div> <div class="periodical"> <em>Nature</em>, Aug 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Sadtler2014</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural constraints on learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nature}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{512}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{423--426}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/nature13665}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/jPCA/">Rotational dynamics in neural population</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/blog-summary/">Blogs syntax summary</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/distill/">a distill-style blog post</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/advanced-images/">a post with advanced image components</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/code-diff/">a post with code diff</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ruixiang Li. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>